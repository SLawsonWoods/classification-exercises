{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34d41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import acquire1\n",
    "import env\n",
    "\n",
    "import prepare\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea1617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire and prepare my dataset\n",
    "train, validate, test = prepare.prep_titanic_data(acquire1.get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63425085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns I won't need\n",
    "train.drop(columns=['sex', 'embark_town'], inplace=True)\n",
    "validate.drop(columns=['sex', 'embark_town'], inplace=True)\n",
    "test.drop(columns=['sex', 'embark_town'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b40772",
   "metadata": {},
   "source": [
    "What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90194b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create baseline\n",
    "train['baseline']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check accuracy of baseline\n",
    "accuracy = (train.survived == train.baseline).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop baseline column after getting the accuracy since we don't need it any longer\n",
    "# Remove two columns name is 'C' and 'D'\n",
    "#df.drop(['C', 'D'], axis = 1) example\n",
    "train.drop('baseline', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b167457",
   "metadata": {},
   "source": [
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d37bf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, class_names=('survived', 'died'), rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27efdd",
   "metadata": {},
   "source": [
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding model score\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0728a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e958cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275976f",
   "metadata": {},
   "source": [
    "4. Compute: Accuracy, true positive rate(recall), false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f7084",
   "metadata": {},
   "source": [
    "Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03e61f",
   "metadata": {},
   "source": [
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb055846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626bddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133289e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create decision tree .pdf\n",
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, class_names=('survived', 'died'), rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b293b4",
   "metadata": {},
   "source": [
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding model score\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.predict(X_train) uses the model to create a prediction for each row in the X_train dataframe and each prediction is\n",
    "# based on the specific features and their values in that given row...one prediction for each row in that dataframe\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ea6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de08ea",
   "metadata": {},
   "source": [
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.(See above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36030e",
   "metadata": {},
   "source": [
    "6. Which model performs better on your in-sample data?\n",
    "The second model with depth of 4 performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2185ba",
   "metadata": {},
   "source": [
    "7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b36513",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ba995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26672f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('baseline', axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a138e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed265bc8",
   "metadata": {},
   "source": [
    "the model is trained on train, and we’ll use that same model to run .predict on X_train, then X_validate, and eventually X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20269d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fe8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And since accuracy isn't everything\n",
    "\n",
    "# Produce y_predictions that come from the X_validate\n",
    "y_pred = clf.predict(X_validate)\n",
    "\n",
    "# Compare actual y values (from validate) to predicted y_values from the model run on X_validate\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e7e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e6fdfc",
   "metadata": {},
   "source": [
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc6f81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "1           5.1          3.5           1.4          0.2  setosa\n",
       "2           4.9          3.0           1.4          0.2  setosa\n",
       "3           4.7          3.2           1.3          0.2  setosa\n",
       "4           4.6          3.1           1.5          0.2  setosa\n",
       "5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acquire the data\n",
    "# read Iris data from pydatset\n",
    "df = data('iris')\n",
    "\n",
    "# convert column names to lowercase, replace '.' in column names with '_'\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "#inspect the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2bbd013",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "450d296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899225c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='species', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['species'])\n",
    "y_train = train.species\n",
    "\n",
    "X_validate = validate.drop(columns=['species'])\n",
    "y_validate = validate.species\n",
    "\n",
    "X_test = test.drop(columns=['species'])\n",
    "y_test = test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9781fc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "80            5.7          2.6           3.5          1.0  versicolor\n",
       "37            5.5          3.5           1.3          0.2      setosa\n",
       "134           6.3          2.8           5.1          1.5   virginica\n",
       "96            5.7          3.0           4.2          1.2  versicolor\n",
       "19            5.7          3.8           1.7          0.3      setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e168b5",
   "metadata": {},
   "source": [
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92575388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c819acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the random forest algorithm to the training data.\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13bb6965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08535086 0.04093506 0.4784486  0.39526548]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548c376",
   "metadata": {},
   "source": [
    "Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebfed2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions classify each flower by its estimated species.\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "671d94d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability of each species, using the training data\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a411e0",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caf4b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "#finding model score\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b98e5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0,  0],\n",
       "       [ 0, 28,  0],\n",
       "       [ 0,  0, 28]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eaa0e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      1.00      1.00        28\n",
      "   virginica       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        84\n",
      "   macro avg       1.00      1.00      1.00        84\n",
      "weighted avg       1.00      1.00      1.00        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1773ae",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe7329cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 1.00\n",
      "True Positive Rate: {}\n",
      "False Positive Rate: {}\n",
      "True Negative Rate: {}\n",
      "False Negative Rate: {}\n",
      "Precision: {1.00}\n",
      "Recall: {1.00}\n",
      "F-1 Score: {1.00}\n",
      "Support: {28}\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "print('True Positive Rate: {}')\n",
    "print('False Positive Rate: {}')\n",
    "print('True Negative Rate: {}')\n",
    "print('False Negative Rate: {}')\n",
    "print('Precision: {1.00}')\n",
    "print('Recall: {1.00}')\n",
    "print('F-1 Score: {1.00}')\n",
    "print('Support: {28}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3e18002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0,  0],\n",
       "       [ 0, 28,  0],\n",
       "       [ 0,  0, 28]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c491d3",
   "metadata": {},
   "source": [
    "Values gathered from confusion matrix above:\n",
    "\n",
    "Setosa\n",
    "TP = 28(cell1) where setosa meets setosa\n",
    "FN = 0 (cell2 + cell3) setosa row other than TP\n",
    "FP = 0 (cell4 + cell7) setosa column other than TP\n",
    "TN = 56 (cell5 + cell6 + cell8 + cell9) everything other than setosa row and column\n",
    "\n",
    "Versicolor\n",
    "TP = 28 (cell5) where versicolor meets versicolor\n",
    "FN = 0 (cell4 + cell6) versicolor row other than TP\n",
    "FP = 0 (cell2 + cell8) versicolor column other than TP\n",
    "TN = 28 (cell1 + cell3 + cell7 + cell9) everything other than versicolor row and column\n",
    "\n",
    "Virginica\n",
    "TP = 28\n",
    "FN = 0\n",
    "FP = 0\n",
    "TN = 56\n",
    "\n",
    "What is the difference between these values and the actual rate of each?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925858c4",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ba242d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 1 change min_samples_leaf to 3 from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bd26570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff0d9591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=3, random_state=123)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the random forest algorithm to the training data.\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3bb1316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07855762 0.0291349  0.48073357 0.41157391]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4288223",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions classify each flower by its estimated species.\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f22c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability of each species, using the training data\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0cc1a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.98\n"
     ]
    }
   ],
   "source": [
    "#finding model score\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eed79acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0,  0],\n",
       "       [ 0, 26,  2],\n",
       "       [ 0,  0, 28]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da0afc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      0.93      0.96        28\n",
      "   virginica       0.93      1.00      0.97        28\n",
      "\n",
      "    accuracy                           0.98        84\n",
      "   macro avg       0.98      0.98      0.98        84\n",
      "weighted avg       0.98      0.98      0.98        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d8f6dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results are decreased accuracy by .02 decreased recall, precision and f-1 by a small \n",
    "# amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d7875e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 2 change min_samples_leaf from 3 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f4f94e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08437474 0.0279723  0.47215105 0.4155019 ]\n",
      "Accuracy of random forest classifier on training set: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      0.93      0.96        28\n",
      "   virginica       0.93      1.00      0.97        28\n",
      "\n",
      "    accuracy                           0.98        84\n",
      "   macro avg       0.98      0.98      0.98        84\n",
      "weighted avg       0.98      0.98      0.98        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=6,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0eccbffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    " #create the object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=6,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44b14ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the random forest algorithm to the training data.\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea81a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe01e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072aeffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results the accuracy and other measurements did not change at all or just in the smallest\n",
    "# amount that did not seem significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3 change max depth from 10 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "338e54d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0850644  0.04051708 0.47973666 0.39468186]\n",
      "Accuracy of random forest classifier on training set: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      1.00      1.00        28\n",
      "   virginica       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        84\n",
      "   macro avg       1.00      1.00      1.00        84\n",
      "weighted avg       1.00      1.00      1.00        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=5, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results this changes the accuracy back to 1 along with precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2ba3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4 change max depth to 2 from 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6de5d0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08833352 0.02775966 0.46983979 0.41406704]\n",
      "Accuracy of random forest classifier on training set: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      0.93      0.96        28\n",
      "   virginica       0.93      1.00      0.97        28\n",
      "\n",
      "    accuracy                           0.98        84\n",
      "   macro avg       0.98      0.98      0.98        84\n",
      "weighted avg       0.98      0.98      0.98        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=6,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=2, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9addf4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results also not much significant change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91258322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5 change the leaf to 2 and keep depth at 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "62dcc0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08040493 0.02838481 0.47775664 0.41345362]\n",
      "Accuracy of random forest classifier on training set: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      0.93      0.96        28\n",
      "   virginica       0.93      1.00      0.97        28\n",
      "\n",
      "    accuracy                           0.98        84\n",
      "   macro avg       0.98      0.98      0.98        84\n",
      "weighted avg       0.98      0.98      0.98        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=4,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=4, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d918b170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result still no significant changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f138b93a",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "The model performs best on max_depth of five and with min_samples_leaf at 1.  I'm not sure why though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20399751",
   "metadata": {},
   "source": [
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "898f06cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "# find accuracy on validate data\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cfdbe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0850644  0.04051708 0.47973666 0.39468186]\n",
      "Accuracy of random forest classifier on training set: 1.00\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      1.00      1.00        28\n",
      "   virginica       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        84\n",
      "   macro avg       1.00      1.00      1.00        84\n",
      "weighted avg       1.00      1.00      1.00        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=5, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "20919399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "# find accuracy on validate data\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fad44f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function should label and plot that array of feature importances if you just pass it \n",
    "# your classifier object.\n",
    "def impurity_decrese_vs_feature_plot(clf):\n",
    "    # Calculate standard deviation of mean impurity across all trees for each feature.\n",
    "    std = np.std([\n",
    "        tree.featureimportances for tree in clf.estimators_], axis=0)\n",
    "\n",
    "    # Caluclate feature importances and label them with the columns from our train set.\n",
    "    forest_importances = pd.Series(clf.featureimportances, index=X_train.columns)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "    ax.set_title(\"Feature importances using MDI\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8994a2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08833352 0.02775966 0.46983979 0.41406704]\n",
      "Accuracy of random forest classifier on training set: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      0.93      0.96        28\n",
      "   virginica       0.93      1.00      0.97        28\n",
      "\n",
      "    accuracy                           0.98        84\n",
      "   macro avg       0.98      0.98      0.98        84\n",
      "weighted avg       0.98      0.98      0.98        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=6,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=2, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e113269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on test set: 0.97\n"
     ]
    }
   ],
   "source": [
    "# find accuracy on validate data\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a55428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't figure out why my validate accuracy doesn't change, might be doing something\n",
    "# wrong here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0108faa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DecisionTreeClassifier' object has no attribute 'estimators_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-dacd1704be09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimpurity_decrese_vs_feature_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-493d9263e60b>\u001b[0m in \u001b[0;36mimpurity_decrese_vs_feature_plot\u001b[0;34m(clf)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Calculate standard deviation of mean impurity across all trees for each feature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     std = np.std([\n\u001b[0;32m----> 6\u001b[0;31m         tree.featureimportances for tree in clf.estimators_], axis=0)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Caluclate feature importances and label them with the columns from our train set.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DecisionTreeClassifier' object has no attribute 'estimators_'"
     ]
    }
   ],
   "source": [
    "impurity_decrese_vs_feature_plot(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500f9d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
