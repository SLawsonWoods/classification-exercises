{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f6ae598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import acquire1\n",
    "import env\n",
    "\n",
    "import prepare\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d6525e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire and prepare my dataset\n",
    "train, validate, test = prepare.prep_titanic_data(acquire1.get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba502ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns I won't need\n",
    "train.drop(columns=['sex', 'embark_town'], inplace=True)\n",
    "validate.drop(columns=['sex', 'embark_town'], inplace=True)\n",
    "test.drop(columns=['sex', 'embark_town'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007c0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664254e2",
   "metadata": {},
   "source": [
    "What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef07fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create baseline\n",
    "train['baseline']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf4fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee43ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check accuracy of baseline\n",
    "accuracy = (train.survived == train.baseline).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5043d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop baseline column after getting the accuracy since we don't need it any longer\n",
    "# Remove two columns name is 'C' and 'D'\n",
    "#df.drop(['C', 'D'], axis = 1) example\n",
    "train.drop('baseline', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a489f",
   "metadata": {},
   "source": [
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79af8f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb680c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, class_names=('survived', 'died'), rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19221c65",
   "metadata": {},
   "source": [
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202cc18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding model score\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fea5143",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06691452",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2933ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0559d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580e4c4",
   "metadata": {},
   "source": [
    "4. Compute: Accuracy, true positive rate(recall), false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba208ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075a71a9",
   "metadata": {},
   "source": [
    "Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab89127",
   "metadata": {},
   "source": [
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13db5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2502ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0651c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e9b557",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create decision tree .pdf\n",
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, class_names=('survived', 'died'), rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f141e513",
   "metadata": {},
   "source": [
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bcfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding model score\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c4519",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.predict(X_train) uses the model to create a prediction for each row in the X_train dataframe and each prediction is\n",
    "# based on the specific features and their values in that given row...one prediction for each row in that dataframe\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37efc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd0c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c41d7ce",
   "metadata": {},
   "source": [
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.(See above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84f5eb",
   "metadata": {},
   "source": [
    "6. Which model performs better on your in-sample data?\n",
    "The second model with depth of 4 performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a44b6f",
   "metadata": {},
   "source": [
    "7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a0720",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12163f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6b50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('baseline', axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ec39bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcca60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb970a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d29040c",
   "metadata": {},
   "source": [
    "the model is trained on train, and weâ€™ll use that same model to run .predict on X_train, then X_validate, and eventually X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868f45f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2badb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587cc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And since accuracy isn't everything\n",
    "\n",
    "# Produce y_predictions that come from the X_validate\n",
    "y_pred = clf.predict(X_validate)\n",
    "\n",
    "# Compare actual y values (from validate) to predicted y_values from the model run on X_validate\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db8184",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1012b7",
   "metadata": {},
   "source": [
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53b77b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "1           5.1          3.5           1.4          0.2  setosa\n",
       "2           4.9          3.0           1.4          0.2  setosa\n",
       "3           4.7          3.2           1.3          0.2  setosa\n",
       "4           4.6          3.1           1.5          0.2  setosa\n",
       "5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#acquire the data\n",
    "# read Iris data from pydatset\n",
    "df = data('iris')\n",
    "\n",
    "# convert column names to lowercase, replace '.' in column names with '_'\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "#inspect the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2126ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3115bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495949da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='species', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['species'])\n",
    "y_train = train.species\n",
    "\n",
    "X_validate = validate.drop(columns=['species'])\n",
    "y_validate = validate.species\n",
    "\n",
    "X_test = test.drop(columns=['species'])\n",
    "y_test = test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2e96818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "80            5.7          2.6           3.5          1.0  versicolor\n",
       "37            5.5          3.5           1.3          0.2      setosa\n",
       "134           6.3          2.8           5.1          1.5   virginica\n",
       "96            5.7          3.0           4.2          1.2  versicolor\n",
       "19            5.7          3.8           1.7          0.3      setosa"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a63b1b5",
   "metadata": {},
   "source": [
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "408d0479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6c9c526b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the random forest algorithm to the training data.\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33ec852b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08535086 0.04093506 0.4784486  0.39526548]\n"
     ]
    }
   ],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eaec50",
   "metadata": {},
   "source": [
    "Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b65c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions classify each flower by its estimated species.\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "756e439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability of each species, using the training data\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caed159",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99d768d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "#finding model score\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a733d0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28,  0,  0],\n",
       "       [ 0, 28,  0],\n",
       "       [ 0,  0, 28]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c08de6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        28\n",
      "  versicolor       1.00      1.00      1.00        28\n",
      "   virginica       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        84\n",
      "   macro avg       1.00      1.00      1.00        84\n",
      "weighted avg       1.00      1.00      1.00        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print classification report\n",
    "cl_report = classification_report(y_train,y_pred)\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b00b212",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame constructor not properly called!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ed751734fd9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcl_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl_report\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame constructor not properly called!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: DataFrame constructor not properly called!"
     ]
    }
   ],
   "source": [
    "cl_report = pd.DataFrame(cl_report, columns=['precision'],['recall'],['f1-score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7794422f",
   "metadata": {},
   "source": [
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9ddcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "print('True Positive Rate: {}')\n",
    "print('False Positive Rate: {}')\n",
    "print('True Negative Rate: {}')\n",
    "print('False Negative Rate: {}')\n",
    "print('Precision: {}')\n",
    "print('Recall: {}')\n",
    "print('F-1 Score: {}')\n",
    "print('Support: {}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b344bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
