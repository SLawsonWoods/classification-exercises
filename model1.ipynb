{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34d41d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pydataset import data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import acquire1\n",
    "import env\n",
    "\n",
    "import prepare\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ea1617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire and prepare my dataset\n",
    "train, validate, test = prepare.prep_titanic(acquire1.get_titanic_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63425085",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns I won't need\n",
    "train.drop(columns=['sex', 'embark_town'], inplace=True)\n",
    "validate.drop(columns=['sex', 'embark_town'], inplace=True)\n",
    "test.drop(columns=['sex', 'embark_town'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b40772",
   "metadata": {},
   "source": [
    "What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90194b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create baseline\n",
    "train['baseline']= 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf3802c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check accuracy of baseline\n",
    "accuracy = (train.survived == train.baseline).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop baseline column after getting the accuracy since we don't need it any longer\n",
    "# Remove two columns name is 'C' and 'D'\n",
    "#df.drop(['C', 'D'], axis = 1) example\n",
    "train.drop('baseline', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b167457",
   "metadata": {},
   "source": [
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bf8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6346c44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d4052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a1343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, class_names=('survived', 'died'), rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b27efdd",
   "metadata": {},
   "source": [
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding model score\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444af75",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de34afe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0728a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e958cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275976f",
   "metadata": {},
   "source": [
    "4. Compute: Accuracy, true positive rate(recall), false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888f7084",
   "metadata": {},
   "source": [
    "Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de03e61f",
   "metadata": {},
   "source": [
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb055846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "clf = DecisionTreeClassifier(max_depth=4, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626bddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X, y)\n",
    "\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133289e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create decision tree .pdf\n",
    "dot_data = export_graphviz(clf, feature_names= X_train.columns, class_names=('survived', 'died'), rounded=True, filled=True, out_file=None)\n",
    "graph = graphviz.Source(dot_data) \n",
    "\n",
    "graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b293b4",
   "metadata": {},
   "source": [
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding model score\n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82e39f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.predict(X_train) uses the model to create a prediction for each row in the X_train dataframe and each prediction is\n",
    "# based on the specific features and their values in that given row...one prediction for each row in that dataframe\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217f1494",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ea6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de08ea",
   "metadata": {},
   "source": [
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.(See above)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f36030e",
   "metadata": {},
   "source": [
    "6. Which model performs better on your in-sample data?\n",
    "The second model with depth of 4 performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2185ba",
   "metadata": {},
   "source": [
    "7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b36513",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ba995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26672f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('baseline', axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188df2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a138e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed265bc8",
   "metadata": {},
   "source": [
    "the model is trained on train, and we’ll use that same model to run .predict on X_train, then X_validate, and eventually X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20269d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()\n",
    "validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0fe8cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a1d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And since accuracy isn't everything\n",
    "\n",
    "# Produce y_predictions that come from the X_validate\n",
    "y_pred = clf.predict(X_validate)\n",
    "\n",
    "# Compare actual y values (from validate) to predicted y_values from the model run on X_validate\n",
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e7e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e6fdfc",
   "metadata": {},
   "source": [
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n",
    "Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n",
    "What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6f81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#acquire the data\n",
    "# read Iris data from pydatset\n",
    "df = data('iris')\n",
    "\n",
    "# convert column names to lowercase, replace '.' in column names with '_'\n",
    "df.columns = [col.lower().replace('.', '_') for col in df]\n",
    "\n",
    "#inspect the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bbd013",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'species'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450d296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899225c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='species', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['species'])\n",
    "y_train = train.species\n",
    "\n",
    "X_validate = validate.drop(columns=['species'])\n",
    "y_validate = validate.species\n",
    "\n",
    "X_test = test.drop(columns=['species'])\n",
    "y_test = test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9781fc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e168b5",
   "metadata": {},
   "source": [
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92575388",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c819acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the random forest algorithm to the training data.\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bb6965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9548c376",
   "metadata": {},
   "source": [
    "Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfed2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions classify each flower by its estimated species.\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d94d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability of each species, using the training data\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a411e0",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding model score\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98e5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa0e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1773ae",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7329cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))\n",
    "print('True Positive Rate: {}')\n",
    "print('False Positive Rate: {}')\n",
    "print('True Negative Rate: {}')\n",
    "print('False Negative Rate: {}')\n",
    "print('Precision: {1.00}')\n",
    "print('Recall: {1.00}')\n",
    "print('F-1 Score: {1.00}')\n",
    "print('Support: {28}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e18002",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c491d3",
   "metadata": {},
   "source": [
    "Values gathered from confusion matrix above:\n",
    "\n",
    "Setosa\n",
    "TP = 28(cell1) where setosa meets setosa\n",
    "FN = 0 (cell2 + cell3) setosa row other than TP\n",
    "FP = 0 (cell4 + cell7) setosa column other than TP\n",
    "TN = 56 (cell5 + cell6 + cell8 + cell9) everything other than setosa row and column\n",
    "\n",
    "Versicolor\n",
    "TP = 28 (cell5) where versicolor meets versicolor\n",
    "FN = 0 (cell4 + cell6) versicolor row other than TP\n",
    "FP = 0 (cell2 + cell8) versicolor column other than TP\n",
    "TN = 28 (cell1 + cell3 + cell7 + cell9) everything other than versicolor row and column\n",
    "\n",
    "Virginica\n",
    "TP = 28\n",
    "FN = 0\n",
    "FP = 0\n",
    "TN = 56\n",
    "\n",
    "What is the difference between these values and the actual rate of each?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff96a1e",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 1 change min_samples_leaf to 3 from 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c673bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=3,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the random forest algorithm to the training data.\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b18f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e955517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions classify each flower by its estimated species.\n",
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611bcecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability of each species, using the training data\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a11dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding model score\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c8847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create confusion matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc490cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b62e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results are decreased accuracy by .02 decreased recall, precision and f-1 by a small \n",
    "# amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b69c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 2 change min_samples_leaf from 3 to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4df6542",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=6,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e100c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad38b47",
   "metadata": {},
   "outputs": [],
   "source": [
    " #create the object\n",
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=6,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ec212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the random forest algorithm to the training data.\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89231cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12ce5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631735b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results the accuracy and other measurements did not change at all or just in the smallest\n",
    "# amount that did not seem significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce582ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3 change max depth from 10 to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=5, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d663d429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results this changes the accuracy back to 1 along with precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02a8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4 change max depth to 2 from 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=6,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=2, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb69c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results also not much significant change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e8f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5 change the leaf to 2 and keep depth at 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b58369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=4,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=4, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465e09f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result still no significant changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b466e9a",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "The model performs best on max_depth of five and with min_samples_leaf at 1.  I'm not sure why though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6264a775",
   "metadata": {},
   "source": [
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce4d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find accuracy on validate data\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dec0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=5, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2593c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find accuracy on validate data\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779b13c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function should label and plot that array of feature importances if you just pass it \n",
    "# your classifier object.\n",
    "def impurity_decrese_vs_feature_plot(clf):\n",
    "    # Calculate standard deviation of mean impurity across all trees for each feature.\n",
    "    std = np.std([\n",
    "        tree.featureimportances for tree in clf.estimators_], axis=0)\n",
    "\n",
    "    # Caluclate feature importances and label them with the columns from our train set.\n",
    "    forest_importances = pd.Series(clf.featureimportances, index=X_train.columns)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "    ax.set_title(\"Feature importances using MDI\")\n",
    "    ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131588e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_model(df):\n",
    "    #create the object\n",
    "    rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=6,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=2, \n",
    "                            random_state=123)\n",
    "    #Fit the random forest algorithm to the training data.\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(rf.feature_importances_)\n",
    "    #Make Predictions classify each flower by its estimated species.\n",
    "    y_pred = rf.predict(X_train)\n",
    "    #Estimate the probability of each species, using the training data\n",
    "    y_pred_proba = rf.predict_proba(X_train)\n",
    "    #finding model score\n",
    "    print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))\n",
    "    #create confusion matrix\n",
    "    confusion_matrix(y_train, y_pred)\n",
    "    #print classification report\n",
    "    print(classification_report(y_train, y_pred))\n",
    "    return\n",
    "    \n",
    "test_my_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f62e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find accuracy on validate data\n",
    "print('Accuracy of random forest classifier on test set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed1c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can't figure out why my validate accuracy doesn't change, might be doing something\n",
    "# wrong here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ece1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "impurity_decrese_vs_feature_plot(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d33616",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3ce4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975d48d0",
   "metadata": {},
   "source": [
    "1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample) - use titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b13238",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('titanic_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54977d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(columns='deck',inplace=True)\n",
    "df.drop(columns='embarked',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb33ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='deck', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dd6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='passenger_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d599ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36440d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace female and male with 0 and 1\n",
    "df.replace(to_replace={'female'}, value= 0, inplace= True)\n",
    "df.replace(to_replace={'male'}, value = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbd5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(to_replace={\"First\"}, value=1, inplace=True)\n",
    "df.replace(to_replace={\"Second\"}, value = 2, inplace=True)\n",
    "df.replace(to_replace={\"Third\"}, value = 3, inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make embark_town numbers\n",
    "df.replace({'embark_town':{'Southampton': 1, 'Cherbourg': 2, 'Queenstown': 3}}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef635ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in null for age, too many just drop column\n",
    "df.age.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f3585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop age column\n",
    "df.drop(columns=\"age\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9baa03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for additional nulls\n",
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11529149",
   "metadata": {},
   "outputs": [],
   "source": [
    "#which embark_town is the most common\n",
    "df['embark_town'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44aab51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill in 2 nulls with mode for embark_town\n",
    "df.embark_town.fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d1fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'sex':'is_male'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f13b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9b2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3874614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dba52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6196b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970db978",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfcc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e05f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fb4af8",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c920d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('True positive rate: 263')\n",
    "print('False positive rate: 44')\n",
    "print('True negative rate: 139')\n",
    "print('False negative rate: 52')\n",
    "print('Precision: .83')\n",
    "print('Recall: .86')\n",
    "print('f1-score: .85')\n",
    "print('support:307')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee32529",
   "metadata": {},
   "source": [
    "4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4a397",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb1c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d1a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5386eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5911e1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('True positive rate: 267')\n",
    "print('False positive rate: 40')\n",
    "print('True negative rate: 123')\n",
    "print('False negative rate: 68')\n",
    "print('Precision: .80')\n",
    "print('Recall: .87')\n",
    "print('f1-score: .83')\n",
    "print('support:307')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff4fd2",
   "metadata": {},
   "source": [
    "5.Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393c83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=20, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604aa1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df91e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d746a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516a31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9da4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3edf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de47bada",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn.score(X_train, y_train)))\n",
    "print('True positive rate: 263')\n",
    "print('False positive rate: 44')\n",
    "print('True negative rate: 106')\n",
    "print('False negative rate: 85')\n",
    "print('Precision: .76')\n",
    "print('Recall: .86')\n",
    "print('f1-score: .80')\n",
    "print('support:307')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae68dd8",
   "metadata": {},
   "source": [
    "6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "When k is set to 5 the accuracy, precision, recall and f-1 score is better on average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afdfe6d",
   "metadata": {},
   "source": [
    "7. Which model performs best on our out-of-sample data from validate?\n",
    "When k is set to 5 precision, recall and f-1 score are better on average than the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0632a7bc",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/calculate-feature-importance-with-python/\n",
    "Permutation Feature Importance for Classification\n",
    "try this for feature importance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7857b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417f0301",
   "metadata": {},
   "source": [
    "1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "243cb316",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd4105e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read titanic data from csv in directory\n",
    "df = pd.read_csv('titanic_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f2103e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_titanic(df):\n",
    "    '''\n",
    "    This function take in the titanic data acquired by get_titanic_data,\n",
    "    Returns prepped train, validate, and test dfs with embarked dummy vars,\n",
    "    deck dropped, and the mean of age imputed for Null values.\n",
    "    '''\n",
    "    \n",
    "    # drop rows where embarked/embark town are null values\n",
    "    df = df[~df.embarked.isnull()]\n",
    "    \n",
    "    # encode embarked using dummy columns\n",
    "    titanic_dummies = pd.get_dummies(df.embarked, drop_first=True)\n",
    "    \n",
    "    # join dummy columns back to df\n",
    "    df = pd.concat([df, titanic_dummies], axis=1)\n",
    "    \n",
    "    # drop the deck column\n",
    "    df = df.drop(columns='deck')\n",
    "    \n",
    "    # split data into train, validate, test dfs\n",
    "    train, validate, test = titanic_split(df)\n",
    "    \n",
    "    # impute mean of age into null values in age column\n",
    "    train, validate, test = impute_mean_age(train, validate, test)\n",
    "    \n",
    "    return train, validate, test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe8ef7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  passenger_id  survived  pclass     sex   age  sibsp  parch  \\\n",
       "0             0             0         0       3    male  22.0      1      0   \n",
       "1             1             1         1       1  female  38.0      1      0   \n",
       "2             2             2         1       3  female  26.0      0      0   \n",
       "3             3             3         1       1  female  35.0      1      0   \n",
       "4             4             4         0       3    male  35.0      0      0   \n",
       "..          ...           ...       ...     ...     ...   ...    ...    ...   \n",
       "886         886           886         0       2    male  27.0      0      0   \n",
       "887         887           887         1       1  female  19.0      0      0   \n",
       "888         888           888         0       3  female   NaN      1      2   \n",
       "889         889           889         1       1    male  26.0      0      0   \n",
       "890         890           890         0       3    male  32.0      0      0   \n",
       "\n",
       "        fare embarked   class deck  embark_town  alone  baseline  \n",
       "0     7.2500        S   Third  NaN  Southampton      0         0  \n",
       "1    71.2833        C   First    C    Cherbourg      0         0  \n",
       "2     7.9250        S   Third  NaN  Southampton      1         0  \n",
       "3    53.1000        S   First    C  Southampton      0         0  \n",
       "4     8.0500        S   Third  NaN  Southampton      1         0  \n",
       "..       ...      ...     ...  ...          ...    ...       ...  \n",
       "886  13.0000        S  Second  NaN  Southampton      1         0  \n",
       "887  30.0000        S   First    B  Southampton      1         0  \n",
       "888  23.4500        S   Third  NaN  Southampton      0         0  \n",
       "889  30.0000        C   First    C    Cherbourg      1         0  \n",
       "890   7.7500        Q   Third  NaN   Queenstown      1         0  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a baseline\n",
    "df['baseline']= 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75496289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. create dummy columns for sex\n",
    "dummy_df = pd.get_dummies(df['sex'], dummy_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda59739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  passenger_id  survived  pclass   sex   age  sibsp  parch  fare  \\\n",
       "0           0             0         0       3  male  22.0      1      0  7.25   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  baseline  female  male  \n",
       "0        S  Third  NaN  Southampton      0         0       0     1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attach the dummy columns to the main df\n",
    "df = pd.concat([df,dummy_df], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef030d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0','sex','passenger_id','sibsp','parch','fare','embarked','class','deck','embark_town'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4e34da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  alone  baseline  female  male\n",
       "0         0       3  22.0      0         0       0     1\n",
       "1         1       1  38.0      0         0       1     0\n",
       "2         1       3  26.0      1         0       1     0\n",
       "3         1       1  35.0      0         0       1     0\n",
       "4         0       3  35.0      1         0       0     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ef82ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill empty values in age with the median age\n",
    "df.age = df.age.fillna(value=df.age.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e1e5e71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check that age has no nulls\n",
    "#df.isna().sum()\n",
    "#df.age.isna().sum()\n",
    "df.age.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a70d050",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aab2b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the object\n",
    "logit = LogisticRegression(C=1, class_weight={0:1, 1:99}, random_state=123, \n",
    "                           intercept_scaling=1, solver='lbfgs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a294e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the object\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2209298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddec0824",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b175a63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33314f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de64b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3178b5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. compare this model to my baseline\n",
    "#check accuracy of baseline\n",
    "accuracy = (train.survived == train.baseline).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e0199e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#my model has an accuracy of 1 and the baseline 62%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dcbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model performance on validate\n",
    "# make predictions\n",
    "\n",
    "y_pred1 = logit.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef27508",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model 1: solver = lbfgs, c = 1\")\n",
    "\n",
    "# accuracy of model 1\n",
    "print('Accuracy: {:.2f}'.format(logit.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix of model 1\n",
    "print(confusion_matrix(y_validate, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report of model 1\n",
    "print(classification_report(y_validate, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c2317",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Try out other combinations of features and models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71c4eff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>alone</th>\n",
       "      <th>baseline</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  alone  baseline  female  male\n",
       "0         0       3  22.0      0         0       0     1\n",
       "1         1       1  38.0      0         0       1     0\n",
       "2         1       3  26.0      1         0       1     0\n",
       "3         1       1  35.0      0         0       1     0\n",
       "4         0       3  35.0      1         0       0     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This go round we willl keep traveling alone and change c to .5 and see what that does\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c02fa991",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e604ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8056ed38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b761cd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fb5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create array of probabilities of survived (survived == 1)\n",
    "\n",
    "y_pred_proba = np.array([i[1] for i in y_pred_proba])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d65ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# scatter plot where x is the probabilities and y is the class (0, 1)\n",
    "ax.scatter(y_pred_proba, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed46b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(df, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ecb2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(C=.5, class_weight={0:1, 1:99}, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5677fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.5, class_weight={0: 1, 1: 99}, random_state=123)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the model\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a43652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Use you best 3 models to predict and evaluate on your validate sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
